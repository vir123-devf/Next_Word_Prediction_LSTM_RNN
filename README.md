## ğŸ§  Next Word Prediction Using LSTM

A deep learning project that predicts the next word in a given sentence using an **LSTM (Long Short-Term Memory)** model.
This project demonstrates the application of **Recurrent Neural Networks (RNNs)** in **Natural Language Processing (NLP)** by learning from the text of *Shakespeareâ€™s Hamlet*.

---

## ğŸ“˜ Project Overview

This project builds a next-word prediction model using an **LSTM-based neural network** trained on literary text.
By analyzing word sequences, the model learns contextual relationships and predicts the most probable next word.

---

## ğŸ§© Workflow

### 1ï¸âƒ£ Data Collection

* The dataset used is **Shakespeareâ€™s â€œHamletâ€**, a classic English text.
* The complexity and richness of the text make it ideal for learning contextual word patterns.

### 2ï¸âƒ£ Data Preprocessing

* The text is **tokenized** using Keras Tokenizer.
* Tokens are converted into sequences and **padded** for uniform length.
* Data is split into **training and validation** sets.

### 3ï¸âƒ£ Model Building

* An **Embedding layer** converts tokens into dense vectors.
* Two **LSTM layers** capture long-term dependencies.
* A **Dense output layer** with **Softmax activation** predicts the next word.

Model summary:

```
Embedding â†’ LSTM â†’ LSTM â†’ Dense (Softmax)
```

### 4ï¸âƒ£ Model Training

* The model is trained on prepared sequences.
* **EarlyStopping** is implemented to avoid overfitting.
* Training progress is monitored via **validation loss**.

### 5ï¸âƒ£ Model Evaluation

* The trained model is evaluated using example sentences.
* The accuracy of next-word predictions is tested on unseen sequences.

### 6ï¸âƒ£ Deployment

* A **Streamlit Web App** allows users to:

  * Enter a sentence.
  * Get the **predicted next word** instantly.
* The app uses the trained model (`next_word_lstm.h5`) and tokenizer (`tokenizer.pickle`).

---

## ğŸ“‚ Project Structure

```
Next_Word_Prediction/
â”‚
â”œâ”€â”€ main.py                # Streamlit application for prediction
â”œâ”€â”€ next_word_lstm.h5      # Trained LSTM model
â”œâ”€â”€ tokenizer.pickle       # Saved tokenizer for text encoding
â”œâ”€â”€ requirements.txt       # List of dependencies
â””â”€â”€ .venv/                 # Virtual environment (optional)
```

---

## ğŸ§  Technologies Used

* **Python 3.x**
* **TensorFlow / Keras**
* **NumPy**
* **Streamlit**
* **Pickle**

---

## ğŸš€ How to Run

1ï¸âƒ£ **Clone this repository**

```bash
git clone https://github.com/your-username/Next_Word_Prediction.git
cd Next_Word_Prediction
```

2ï¸âƒ£ **Install dependencies**

```bash
pip install -r requirements.txt
```

3ï¸âƒ£ **Run the Streamlit app**

```bash
streamlit run main.py
```

4ï¸âƒ£ **Use the Web Interface**

* Enter a phrase like:

  > "To be or not to"
* Get output:

  > Predicted next word â†’ *"be"*

 <img width="1545" height="860" alt="image" src="https://github.com/user-attachments/assets/e6b0cb5f-7ed8-4170-a275-a4cf47982e7d" />


---

## ğŸ“ˆ Results

The model achieves meaningful predictions on literary text, demonstrating the capability of LSTM networks to understand linguistic context.

---

## ğŸ§‘â€ğŸ’» Author

**Virendra Badgotya**
B.Tech in Electrical Engineering | SVNIT Surat
ğŸ”— [GitHub](https://github.com/vir123-devf) | [LinkedIn](https://www.linkedin.com/in/virendra-badgotya-ai/)

---

Would you like me to include an **example screenshot section** (for your Streamlit app interface) in the README as well? It can make your GitHub page look more appealing.
